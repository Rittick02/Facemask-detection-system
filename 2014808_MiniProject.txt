# Import Libraries

import numpy as np 
import pandas as pd 
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import SGD
import os
import pickle

# Visual Representation of Dataset

image = cv2.imread('C:\\Users\\user\\Mini Project VI\\Dataset\\without_mask\\18.png',cv2.IMREAD_GRAYSCALE)
image = cv2.resize(image,[150,150])
plt.imshow(image,cmap='gray')

# Preprocessing of Training Data

# main_dir = "C:\Users\user\Mini Project V\Dataset"
# train_dir = "train"
path_train = 'C:\\Users\\user\\Mini Project VI\\Dataset'

for name in os.listdir(path_train):
    for p in os.listdir(os.path.join(path_train,name)):
        category = p.split(".")[0]
        print(name," ",category)
        img_array = cv2.imread(os.path.join(os.path.join(os.path.join(path_train,name)),p),cv2.IMREAD_GRAYSCALE)
        print(img_array)
        new_img_array = cv2.resize(img_array, dsize=(150, 150))
        plt.imshow(new_img_array,cmap="gray")
        break

# Processing of Training Data

X = []
y = []

def create_test_data(path):
    count=0
    for name in os.listdir(path):
        for p in os.listdir(os.path.join(path,name)):
            print(name," ",count)
            img_array = cv2.imread(os.path.join(os.path.join(path,name),p),cv2.IMREAD_GRAYSCALE)
            print(img_array)
            new_img_array = np.array(cv2.resize(img_array, dsize=(150, 150)))
            X.append(new_img_array)
            y.append(count)
        count+=1

# Conversion of Image to Array Format

create_test_data(path_train)
X = np.array(X).reshape(-1, 150,150,1)
y = np.array(y)

# Print The Different Count of Data

print(y)

# Normalize Data

X = X/255.0

# Defining of The CNN Model

model = Sequential()
# Adds a densely-connected layer with 64 units to the model:
model.add(Conv2D(64,(3,3), activation = 'relu', input_shape = X.shape[1:]))
model.add(MaxPooling2D(pool_size = (2,2)))

model.add(Conv2D(64,(3,3), activation = 'relu'))
model.add(MaxPooling2D(pool_size = (2,2)))


model.add(Conv2D(64,(3,3), activation = 'relu'))
model.add(MaxPooling2D(pool_size = (2,2)))

model.add(Flatten())

model.add(Dense(32, activation='relu'))

model.add(Dense(1, activation='sigmoid'))

#model.summary()

model.compile(optimizer="adam",
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Model Training

# Model Training Start
model.fit(
    X, y, 
    epochs=15, 
    batch_size=50, 
    validation_split=0.2, 
    shuffle=True)

# Preprocessing of Test Data

train_dir = "Test"
main_dir = 'C:/Users/user/Mini Project VI'
path = os.path.join(os.path.join(main_dir,train_dir))


X_test = []
id_line = []
def create_test1_data(path):
    for name in os.listdir(path):
        for p in os.listdir(os.path.join(path,name)):
            id_line.append(p.split(".")[0])
            img_array = cv2.imread(os.path.join(os.path.join(path,name),p),cv2.IMREAD_GRAYSCALE)
            new_img_array = cv2.resize(img_array, dsize=(150, 150))
            X_test.append(new_img_array)
create_test1_data(path)
X_test = np.array(X_test).reshape(-1,150,150,1)
X_test = X_test/255
X_test

# Predict on Test Data

predictions = model.predict(X_test)

# Prediction Result

predicted_val = [int(round(p[0])) for p in predictions]
name = [os.listdir('C:/Users/user/Mini Project VI/Dataset')[i] for i in predicted_val]
# print('Match Found From Testing.\n',name)

# Submission and Output Test Sample

submission_df = pd.DataFrame({'name':name, 'id':id_line, 'label':predicted_val})
submission_df

# Saving the Model

# model = ...
model.save("models.h5")

# Load the Model

from tensorflow import keras
model = keras.models.load_model("models.h5")

# Write Result to CSV File

submission_df.to_csv("submission.csv", index=False)

